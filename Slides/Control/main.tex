\documentclass{beamer}

\input{settings.tex}


\title{Stabilizing Control}
\subtitle{Control Theory, Lecture 3}
\author{by Sergei Savin}
\centering
\date{\mydate}



\begin{document}
\maketitle


%\begin{frame}{Content}
%
%\begin{itemize}
%\item Stabilizing control
%\item Error dynamics
%\item Affine trajectory tracking
%\item Point-to-point control
%\item Pure state feedback
%\item Read more
%\end{itemize}
%
%\end{frame}



\begin{frame}{Changing stability}
% \framesubtitle{O}
\begin{flushleft}

Here are two LTIs:

\begin{equation}
    \dot{x} = 2 x
\end{equation}

\begin{equation}
    \dot{x} = 2 x + u
\end{equation}

First one is autonomous and unstable. Second one is not autonomous, and we won't know whether or not the solution converges to zero, until we know what $u$ is.

\bigskip

If we pick $u=0$, the result is an unstable equation. But we can also pick $u$ such that the resulting dynamics is stable, such as $u=-3x$:

\begin{equation}
    \dot{x} = 2 x + u = 2 x - 3x = -x
\end{equation}

\begin{block}{ }
So, we can use \emph{control input} $u$ to change stability of the system!
\end{block}


\end{flushleft}
\end{frame}





\begin{frame}{Stabilizing control}
% \framesubtitle{O}
\begin{flushleft}

\begin{definition}
The problem of finding control law $\bo{u}$ that make a certain solution $\bo{x}^*$ of dynamical system $\dot{\bo{x}} = \bo{f}(\bo{x}, \bo{u})$ stable is called \emph{stabilizing control problem}
\end{definition}

\bigskip

This is true for both linear and non-linear systems. But for linear systems we can get a lot more details about this problem, if we restrict our choice of control law.



\end{flushleft}
\end{frame}



\begin{frame}{Linear control}
\framesubtitle{Closed-loop system}
\begin{flushleft}

Consider an LTI system:

\begin{equation}
    \dot{\bo{x}} = \bo{A}\bo{x} + \bo{B}\bo{u}
\end{equation}

and let us chose \emph{control as a linear function of the state} $x$:

\begin{equation}
    \bo{u} = -\bo{K}\bo{x}
\end{equation}

We call matrix $\bo{K}$ \emph{control gain}. Thus, we know how the system is going to look when the control is applied:

\begin{equation}
    \dot{\bo{x}} = \bo{A}\bo{x} - \bo{B}\bo{K}\bo{x}
\end{equation}
\begin{equation}
\label{eq:closed_loop}
    \dot{\bo{x}} = (\bo{A} - \bo{B}\bo{K})\bo{x}
\end{equation}

Note that \eqref{eq:closed_loop} is an autonomous system. We call this a \emph{closed-loop} system.

\end{flushleft}
\end{frame}



\begin{frame}{Linear control}
%\framesubtitle{Stability of the closed-loop system}
\begin{flushleft}

We can analyse stability of $\dot{\bo{x}} = (\bo{A} - \bo{B}\bo{K})\bo{x}$:

\begin{block}{Stability condition for LTI closed-loop system}
The real parts of the eigenvalues of the matrix $(\bo{A} - \bo{B}\bo{K})$ should be negative for asymptotic stability, or non-positive for stability in the sense of Lyapunov.
\end{block}

\begin{block}{Hurwitz matrix}
	If square matrix $\bo{M}$ has eigenvalues with strictly negative real parts, it is called Hurwitz. We will denote it as $\bo{M} \in \mathcal{H}$.
\end{block}

%\bigskip

So, all you need to do is to find such $\bo{K}$ that $(\bo{A} - \bo{B}\bo{K})$ is Hurwitz, and you made a an asymptotically stable closed-loop system!

\end{flushleft}
\end{frame}




\begin{frame}{Scalar case}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Let us consider the following system:
		
		\begin{equation}
			\dot x = a x + b u
		\end{equation}
	
		we can choose the following linear control law: $u = - k x$. The close loop system for this example is:
		
		\begin{equation}
			\dot x = (a- bk) x
		\end{equation}		
	
		The solution to the closed-loop system is:
		
		\begin{equation}
			x(t) =  x_0 e^{(a- bk)t}
		\end{equation}		
		
		As long as $a- bk < 0$, the solution is converging to zero. Since we can pick $k$, we can choose it so that $a- bk = -q$, where $q$ is a positive number. Then, we pick $k = \frac{q+a}{b}$, giving us a stable system with eigenvalue $-q$.
		
	\end{flushleft}
\end{frame}



\begin{frame}{Multivariable case}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Let us consider the following system:
		%
		\begin{equation}
			\begin{bmatrix}
				\dot x_1 \\ \dot x_2
			\end{bmatrix} 
		= 
		\begin{bmatrix}
			a_{11} & a_{12} \\ 0 & a_{22}
		\end{bmatrix}
		\begin{bmatrix}
			x_1 \\ x_2
		\end{bmatrix} 
	+ 
		\begin{bmatrix}
			b \\ 0
		\end{bmatrix}
		u
		\end{equation}
		
		With control law:
		%
		\begin{equation}
			u
			= 
			-
			\begin{bmatrix}
				k_1 & k_2
			\end{bmatrix}
			\begin{bmatrix}
				x_1 \\ x_2
			\end{bmatrix} 
		\end{equation}
		
		Close-loop system is:
		%
		\begin{equation}
			\begin{bmatrix}
				\dot x_1 \\ \dot x_2
			\end{bmatrix} 
			= 
			\begin{bmatrix}
				a_{11}-b k_1 & a_{12}-b k_2 \\ 0 & a_{22}
			\end{bmatrix}
			\begin{bmatrix}
				x_1 \\ x_2
			\end{bmatrix} 
		\end{equation}
		
		The eigenvalues of the closed-loop system are $a_{11}-b k_1$ and $a_{22}$.  The second eigenvalue cannot be influenced by the choice of control gains. If $a_{22} < 0$, we need to pick $k_1$, such as  $a_{11}-b k_1 = -q$, where $q$ is a positive number: $k_1 = \frac{q + a_{11}}{b}$.
		
	\end{flushleft}
\end{frame}





\begin{frame}{Spring-mass-damper, 1}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Let us consider a spring-mass-damper:
		%
		\begin{equation}
			\ddot y + \mu \dot y + c y = 0
		\end{equation}
		
		The eq. can be re-written in state-space form with a change of variables $x_1 = y$ and $x_2 = \dot y$:
		%
		\begin{equation}
			\begin{bmatrix}
				\dot x_1 \\ \dot x_2
			\end{bmatrix} 
			= 
			\begin{bmatrix}
				0 & 1 \\ - c & -\mu
			\end{bmatrix}
			\begin{bmatrix}
				x_1 \\ x_2
			\end{bmatrix}
		\end{equation}
		
		
		It is easy compute eigenvalues of a 2 by 2 matrix, using its determinant $\text{det}$ and trace $\text{tr}$:
		%
		\begin{equation}
			\lambda = \frac{\text{tr} \pm \sqrt{\text{tr}^2 - 4 \text{det}}}{2} 
		\end{equation}
		
		Here $\text{det} = c$ and $\text{tr} = -\mu$:
		%
		\begin{equation}
			\lambda = \frac{-\mu \pm \sqrt{\mu^2 - 4 c}}{2} 
		\end{equation}
		
	\end{flushleft}
\end{frame}


\begin{frame}{Spring-mass-damper, 2}
	% \framesubtitle{O}
	\begin{flushleft}
		
		Let us analyze eigenvalues $\lambda = \frac{-\mu \pm \sqrt{\mu^2 - 4 c} }{2}$. We can see that if \textcolor{mydarkgreen}{$\mu > 0$} and \textcolor{mydarkgreen}{$ c > 0$}, there are only two scenarios: 
		
		\begin{enumerate}
			\item $\mu^2 - 4c \geq 0$, in which case $\sqrt{\mu^2 - 4c} \leq \mu$, the eigenvalues are purely real and \textcolor{mydarkgreen}{negative}.
			\item $\mu^2 - 4c < 0$, in which case $\sqrt{\mu^2 - 4c}$ is a purely imaginary number, the eigenvalues are complex with \textcolor{mydarkgreen}{negative real parts}.
		\end{enumerate}
		
		If $\mu > 0$ and \textcolor{myblue}{$c = 0$}, then $\lambda_1 = -\mu$, $\lambda_2 = 0$, hence the system is \textcolor{myblue}{marginally stable}.
		
		If \textcolor{myblue}{$\mu = 0$} and $c > 0$, then $\lambda = \pm i \sqrt{c}$, hence the system is \textcolor{myblue}{marginally stable}.
		
	\end{flushleft}
\end{frame}



\begin{frame}{Spring-mass-damper, 3}
	\begin{flushleft}
		
		
		If $\mu \geq 0$ and \textcolor{red}{$c < 0$}, then $\sqrt{\mu^2 - 4c} \geq \mu$, and eigenvalues are purely real and one of them is \textcolor{red}{positive}, the system is unstable. If \textcolor{red}{$\mu < 0$} and \textcolor{red}{$c < 0$} at least one of the eigenvalues is still \textcolor{red}{positive}.
		
		\bigskip
		
		If \textcolor{red}{$\mu < 0$} and $c \geq 0$, then again there are only two scenarios: 
		
		\begin{enumerate}
			\item $\mu^2 - 4c \geq 0$, in which case $\sqrt{\mu^2 - 4c} \leq \mu$, the eigenvalues are purely real and \textcolor{red}{positive}.
			\item $\mu^2 - 4c < 0$, in which case $\sqrt{\mu^2 - 4c}$ is a purely imaginary number, the eigenvalues are complex with \textcolor{red}{positive real parts}.
		\end{enumerate}
		
		\begin{definition}
			Iff $\mu \geq 0$ and $c \geq 0$ the system $\ddot y + \mu \dot y + c y = 0$ is stable.
		\end{definition}
		
	\end{flushleft}
\end{frame}



\begin{frame}{PD control, 1}
	\begin{flushleft}
		
		Let us consider a spring-mass-damper:
		%
		\begin{equation}
			\ddot y + \mu \dot y + c y = u
		\end{equation}
		
		We can propose the feedback control in the form:
		%
		\begin{equation}
			u = -k_d \dot y  -k_p y 
		\end{equation}
		%
		this is called a \emph{proportional-differential controler}, often shortened as \emph{PD controller}; $k_d$ is a differential coefficient and $k_p$ is a proportional coefficient. The closed-loop system is:
		%
		\begin{align}
			\ddot y + (\mu + k_d) \dot y + (c+k_p) y = 0
		\end{align}
		
		The eigenvalues are:
		%
		\begin{align}
			\lambda &= \frac{-(\mu + k_d) \pm d}{2} 
			\\
			d &= \sqrt{(\mu + k_d)^2 - 4 (c+k_p)}
		\end{align}
		
		
	\end{flushleft}
\end{frame}



\begin{frame}{PD control, 2}
	\begin{flushleft}
		
		Given $c = 40$ and $\mu = 8$, assume that we want the closed-loop system to have eigenvalues $\lambda_1 = -4$ and $\lambda_2 = -20$.
		%
		\begin{align}
			16 = \lambda_1 - \lambda_2= \frac{-(\mu + k_d) +d}{2} - \frac{-(\mu + k_d) - d}{2}  = d
		\end{align}
		%
		It follows that:
		%
		\begin{align}
			-4 = \lambda_1 = \frac{-(\mu + k_d) + 16}{2}
			\\
			-(\mu + k_d) + 16 = -8
			\\
			k_d  = 16
		\end{align}
		
		
		Also we can write:
		%
		\begin{align}
			d = \sqrt{(\mu + k_d)^2 - 4 (c+k_p)}
			\\
			16^2 = 24^2 - 4 (40 + k_p)
			\\
			k_p = 320 / 4 - 40 = 40
		\end{align}
		
		
	\end{flushleft}
\end{frame}







\begin{frame}{Pole-placement}
	\begin{flushleft}
		
		The method of finding control gains in such a way that the closed-loop system has desired eigenvalues is called \emph{pole placement}.
		
		\bigskip
		
		As the earlier example illustrated, it is not easy to do manually. However, there is software that finds such control gains automatically.
		
		\bigskip
		
		In MATLAB there is a function \texttt{K = place(A,B,p)}, where \texttt{p} are the desired eigenvalues of \texttt{(A-B*K)}.
		
		
	\end{flushleft}
\end{frame}










\begin{frame}{Trajectory tracking, 1}
	\begin{flushleft}
		
		Let the function $\bo{x}^* = \bo{x}^*(t)$ and control $\bo{u}^* = \bo{u}^*(t)$ be a solution to the system $\dot{\bo{x}} = \bo{A}\bo{x} + \bo{B}\bo{u}$, meaning:
		%
		\begin{equation}
			\dot{\bo{x}}^* = \bo{A}\bo{x}^* + \bo{B}\bo{u}^*
		\end{equation}
	
		We call $\bo{x}^*(t)$ a \emph{reference} or a \emph{reference input} and $\bo{u}^*(t)$ is a \emph{feed-forward control}.
		
		\bigskip
		
		We can try to find a control law that would stabilize this reference trajectory. We begin by finding the difference between $\dot{\bo{x}}^*$ and $\dot{\bo{x}}$:
		%
		\begin{equation}
			\dot{\bo{x}}^* - \dot{\bo{x}}= \bo{A}(\bo{x}^*-\bo{x}) + \bo{B}(\bo{u}^*-\bo{u})
		\end{equation}
		
		We define new variables: $\bo{e} = \bo{x}^* - \bo{x}$ and $\bo{v} = \bo{u}^* - \bo{u}$:
		%
		\begin{equation}
			\dot{\bo{e}} = \bo{A}\bo{e} + \bo{B}\bo{v}
		\end{equation}
		
	\end{flushleft}
\end{frame}



\begin{frame}{Trajectory tracking, 2}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		We call $\bo{e}$ \emph{control error} and the equation $\dot{\bo{e}} = \bo{A}\bo{e} + \bo{B}\bo{v}$ is \emph{error dynamics}.
		
		\bigskip
		
		With that, we are back to the familiar problem: find a control law $\bo{v} = -\bo{K}\bo{e}$ that makes the closed-loop system stable:
		%
		\begin{equation}
			\dot{\bo{e}} = (\bo{A} - \bo{B}\bo{K}) \bo{e}
		\end{equation}
		
		In the original variables, the control law takes form:
		%
		\begin{equation}
			\bo{u} = \bo{K}(\bo{x}^* - \bo{x}) + \bo{u}^*
		\end{equation}
		
	\end{flushleft}
\end{frame}




\begin{frame}{Trajectory tracking, 3}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		If there exists a feed-forwad control $\bo{u}^*$ satisfying $\dot{\bo{x}}^* = \bo{A}\bo{x}^* + \bo{B}\bo{u}^*$ for a given reference signal $\bo{x}^*$, then we can easily find such $\bo{u}^*$  via pseudo-inverse:
		
		\begin{equation}
			 \bo{u}^* = \bo{B}^+(\dot{\bo{x}}^*  - \bo{A}\bo{x}^*)
		\end{equation}				
		
		If the desired trajectory is constant $\bo{x}^*(t) = \bo{x}_d$ (we are trying to move a system to a new position in the state-space), then the feed-forward control takes the form:
		
		\begin{equation}
			\bo{u}^* = -\bo{B}^+\bo{A}\bo{x}_d
		\end{equation}	
		
		
	\end{flushleft}
\end{frame}



\begin{frame}{New input}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Consider the system $\dot{\bo{x}} = \bo{A}\bo{x} + \bo{B}\bo{u}$ and control law $\bo{u} = \bo{K}(\bo{x}^*(t) - \bo{x}) + \bo{u}^*(t)$. We can find the expression for the resulting system:
		
		\begin{align}
			\dot{\bo{x}} = \bo{A}\bo{x} + \bo{B}\bo{K}(\bo{x}^*(t) - \bo{x}) + \bo{B}\bo{u}^*(t) \\
			\dot{\bo{x}} = (\bo{A}- \bo{B}\bo{K})\bo{x} +\bo{B}\bo{K}\bo{x}^*(t) + \bo{B}\bo{u}^*(t)
		\end{align}		
		
		Assuming that $\bo{u}^*(t) = 0$ gives us a simplified system:
		
		\begin{align}
			\dot{\bo{x}} =  (\bo{A}- \bo{B}\bo{K})\bo{x} +\bo{B}\bo{K}\bo{x}^*(t)
		\end{align}				
		
		Here we can see that $\bo{x}^*(t)$ acts as a new input. We can analyse input responce of this system.
		
	\end{flushleft}
\end{frame}




\begin{frame}{Where we are}
	
	% TODO: \usepackage{graphicx} required
	\begin{figure}
		\centering
		\includegraphics[width=1.00\linewidth]{"Scheme colors"}
	\end{figure}
	

\end{frame}





\begin{frame}{Literature}

\begin{itemize}
	
	
	\item Nise, N.S. Control systems engineering. John Wiley \& Sons. (4.5 The General Second-Order System)	
	
	\item \bref{https://apmonitor.com/pdc/index.php/Main/ModelSimulation}{Dynamic Simulation in Python}
\end{itemize}
\end{frame}




\myqrframe

\end{document}
